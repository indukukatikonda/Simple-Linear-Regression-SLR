{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "__JhGBLlJl8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset from a CSV file (replace with your dataset path)\n",
        "file_path = '/content/BostonHousing.csv'  # e.g., 'C:/datasets/housing_data.csv'\n"
      ],
      "metadata": {
        "id": "6yVLjzND-gK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv(file_path)  # Define df in this block so it is accessible\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "\n",
        "    # Display the first few rows of the dataframe\n",
        "    print(df.head())  # Use .head() to display the top 5 rows of the dataframe\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file at {file_path} was not found.\")\n",
        "    exit()\n"
      ],
      "metadata": {
        "id": "4HjwcmLc_2Jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'medv' is the target column (modify if your dataset is different)\n",
        "if 'medv' not in df.columns:\n",
        "    print(\"Error: The target column 'medv' does not exist in the dataset.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "bwou1GnT-xni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect column names\n",
        "print(\"Column names in the dataset:\")\n",
        "print(df.columns)\n"
      ],
      "metadata": {
        "id": "IVETrmqyJyRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the feature matrix (X) and target vector (y)\n",
        "X = df.drop(columns=['medv'])\n",
        "y = df['medv']\n"
      ],
      "metadata": {
        "id": "YRAQcgdjJ3Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "if df.isnull().values.any():\n",
        "    print(\"Warning: Missing values detected. Dropping missing values...\")\n",
        "    df = df.dropna()"
      ],
      "metadata": {
        "id": "CothJLvoKFOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that X and y have compatible shapes\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "if X.shape[0] != y.shape[0]:\n",
        "    print(f\"Error: X and y have incompatible shapes. X has {X.shape[0]} rows, but y has {y.shape[0]} rows.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "LZ3-ri_RKJ0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n"
      ],
      "metadata": {
        "id": "lFih2poWQ3sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the data (optional)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "u98o5xeCQ9hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add intercept (bias) to X_train and X_test\n",
        "X_train_b = np.c_[np.ones((X_train_scaled.shape[0], 1)), X_train_scaled]\n",
        "X_test_b = np.c_[np.ones((X_test_scaled.shape[0], 1)), X_test_scaled]\n"
      ],
      "metadata": {
        "id": "zYBSVJ6TRFg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Analytical Solution (Normal Equation)\n",
        "theta_analytic = np.linalg.inv(X_train_b.T @ X_train_b) @ X_train_b.T @ y_train\n",
        "y_pred_analytic = X_test_b @ theta_analytic\n"
      ],
      "metadata": {
        "id": "3YBIhluVRKSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate performance metrics for the analytical solution\n",
        "mse_analytic = mean_squared_error(y_test, y_pred_analytic)\n",
        "r2_analytic = r2_score(y_test, y_pred_analytic)\n",
        "\n",
        "print(\"\\nAnalytic Solution:\")\n",
        "print(f\"Theta (coefficients): {theta_analytic}\")\n",
        "print(f\"Mean Squared Error: {mse_analytic}\")\n",
        "print(f\"R²: {r2_analytic}\")"
      ],
      "metadata": {
        "id": "5Xu9HA3LRO1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Gradient Descent Implementation (Full-Batch)\n",
        "theta_gd = np.zeros(X_train_b.shape[1])\n",
        "alpha = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    gradients = 2 / len(X_train_b) * X_train_b.T @ (X_train_b @ theta_gd - y_train)\n",
        "    theta_gd -= alpha * gradients\n",
        "\n",
        "y_pred_gd = X_test_b @ theta_gd\n"
      ],
      "metadata": {
        "id": "AZH9bRuZRURy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate performance metrics for gradient descent\n",
        "mse_gd = mean_squared_error(y_test, y_pred_gd)\n",
        "r2_gd = r2_score(y_test, y_pred_gd)\n",
        "\n",
        "print(\"\\nGradient Descent Solution (Full-Batch):\")\n",
        "print(f\"Theta (coefficients): {theta_gd}\")\n",
        "print(f\"Mean Squared Error: {mse_gd}\")\n",
        "print(f\"R²: {r2_gd}\")\n"
      ],
      "metadata": {
        "id": "F_maieR6RYvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the predicted values vs actual values\n",
        "plt.scatter(y_test, y_pred_analytic, label='Analytic', alpha=0.5)\n",
        "plt.scatter(y_test, y_pred_gd, label='Gradient Descent', alpha=0.5)\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='black', lw=2)\n",
        "plt.xlabel('Actual Prices')\n",
        "plt.ylabel('Predicted Prices')\n",
        "plt.legend()\n",
        "plt.title('Comparison of Predicted Prices vs Actual Prices')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "McbzTHcTRg9X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}